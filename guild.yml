- model: eyepacs
  description: DR grading on eyepacs
  sourcecode:
    # Source code config at the model level applies to all
    # operations. In this case we want to copy all of the text files
    # (the default configuration) but exclude everything under 'data'.
    - exclude: 'data/*'
    - exclude: 'experiments/*'

  operations:
    train:
      # The default 'main' attribute is 'train' based on the
      # operation name. While we could omit this below, it's good
      # practice to specify it.
      main: train

      # In this configuration, we require the project 'data'
      # directory. Guild creates a symbolic link named 'data' to
      # this directory in each run directory for the operation.
      requires:
        - file: data
        - file: experiments
        - file: utils
        - file: models
        - file: results

    train_multi_task:
      # The default 'main' attribute is 'train' based on the
      # operation name. While we could omit this below, it's good
      # practice to specify it.
      main: train_multi_task
      # In this configuration, we require the project 'data'
      # directory. Guild creates a symbolic link named 'data' to
      # this directory in each run directory for the operation.
      requires:
        - file: data
        - file: experiments
        - file: utils
        - file: models
        - file: results

    test_experiment_class:
      description:
        This is a test experiment with one epoch to check that guild.ai works
      steps:
        - run: train
          flags:
            - csv_train='train.csv'
            - lr=0.01
            - optimizer=['sgd','adam']
            - n_epochs=3
            - save_model=True

########################################################################################################################
    template_class_experiment:
      description:
        This is a template for a classification experiment.
        Write here conclusions.
      steps:
        - run: train
          flags:
            - csv_train=train.csv
            - model_name=[resnet18_cifar,resnet50_cifar,resnet18,resnet50,resnext50,resnext101]
            - pretrained=[True,False]
            - loss_fn=[CE,ULS,GLS,trivial_ot]
            - lr=0.001
            - batch_size=8
            - optimizer=[adam,sgd]
            - oversample=[1/1/1,1/2/1/6/7]
            - n_epochs=100
            - patience=20
            - decay_f=0.1
            - metric=[kappa,kappa_auc_avg]
            - save_model=False

########################################################################################################################
    dr_grade:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - csv_train=[train_all_1.csv,train_all_2.csv,train_all_3.csv,train_all_4.csv]
            - model_name=resnet50
            - pretrained=True
            - load_checkpoint=[models/resnet50_eyepacs]
            - base_loss=[ce,gls,focal_loss]
            - lambd=[10]
            - exp=[1]
            - lr=0.0001
            - batch_size=8
            - optimizer=sgd
            - oversample=1/4/2/2/7
            - decay_f=0.1
            - metric=kappa_auc_avg
            - save_model=False
            - n_epochs=50
            - patience=5
########################################################################################################################
    dr_grade_OD:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - model_name=resnet50
            - pretrained=True
            - load_checkpoint=[models/resnet50_eyepacs]
            - base_loss=[gls,ce,focal_loss]
            - lr=0.0001
            - lambd=[10]
            - exp=[1]
            - batch_size=8
            - optimizer=sgd
            - oversample=1/4/2/2/7 # 1/2/2/4/9 for UW
            - decay_f=0.1
            - metric=kappa_auc_avg
            - save_model=False
            - n_epochs=50
            - patience=5
            - csv_train=[train_od_1.csv,train_od_2.csv,train_od_3.csv,train_od_4.csv] #
########################################################################################################################
    dr_grade_MAC:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - model_name=resnet50
            - pretrained=True
            - load_checkpoint=[models/resnet50_eyepacs]
            - base_loss=[gls,ce,focal_loss]
            - lr=0.0001
            - lambd=[10]
            - exp=[1]
            - batch_size=8
            - optimizer=sgd
            - oversample=1/4/2/2/7 # 1/2/2/4/9 for UW
            - decay_f=0.1
            - metric=kappa_auc_avg
            - save_model=False
            - n_epochs=50
            - patience=5
            - csv_train=[train_mac_1.csv,train_mac_2.csv,train_mac_3.csv,train_mac_4.csv] #
########################################################################################################################
########################################################################################################################
########################################################################################################################
    dr_grade_ALL_UW:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - model_name=[resnet50]
            - pretrained=True
            - base_loss=[focal_loss]#ce,gls,focal_loss
            - load_checkpoint=[models/resnet50_eyepacs,experiments/best_both_f3] # experiments/best_kappa_both_20Mar,
            - lr=0.0001
            - lambd=[1,10]
            - exp=[1]
            - batch_size=8
            - optimizer=sgd
            - oversample=[1/1/1/3/8] # for UW_all
            - decay_f=0.1
            - metric=[kappa_auc_avg]
            - save_model=False
            - n_epochs=50
            - patience=5
            - csv_train=[train_all_1_UW.csv,train_all_2_UW.csv,train_all_3_UW.csv,train_all_4_UW.csv]
########################################################################################################################
    dr_grade_MAC_UW:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - model_name=[resnet50]
            - pretrained=True
            - base_loss=[ce,gls,focal_loss]
            - load_checkpoint=[models/resnet50_eyepacs]
            - lr=0.0001
            - lambd=[10]
            - exp=[1]
            - batch_size=8
            - optimizer=sgd
            - oversample=[1/2/2/4/9] # for UW
            - decay_f=0.1
            - metric=[kappa_auc_avg]
            - save_model=False
            - n_epochs=50
            - patience=5
            - csv_train=[train_mac_1_UW.csv,train_mac_2_UW.csv,train_mac_3_UW.csv,train_mac_4_UW.csv] #
########################################################################################################################
    dr_grade_OD_UW:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - model_name=[resnet50]
            - pretrained=True
            - base_loss=[ce,gls,focal_loss]
            - load_checkpoint=[experiments/best_both_f3] # ,models/resnet50_eyepacs,
            - lr=0.0001
            - lambd=[10]
            - exp=[1]
            - batch_size=8
            - optimizer=sgd
            - oversample=[1/2/2/4/9] # for UW
            - decay_f=0.1
            - metric=[kappa_auc_avg]
            - save_model=False
            - n_epochs=50
            - patience=5
            - csv_train=[train_od_1_UW.csv,train_od_2_UW.csv,train_od_3_UW.csv,train_od_4_UW.csv]

########################################################################################################################
########################################################################################################################
#    dr_grade_quality_multi_task_OS:
#      description:
#        This is the main experiment on dr grading
#      steps:
#        - run: train_multi_task
#          flags:
#            - n_classes=18
#            - model_name=[resnext50_sws] #resnet50_sws,resnet50,,resnext50
#            - pretrained=True
#            - base_loss=[ce] #,focal_loss
#            - load_checkpoint=[no]
#            - lr=[0.0001]
#            - lambd=0
#            - exp=1
#            - batch_size=8
#            - optimizer=sgd  # ------------------------------------
##            - oversample=10/4/1/1/1
##            - oversample_task=field_def
#            - oversample=8/3/1/1/1
#            - oversample_task=clarity
#            - decay_f=0.1
#            - metric=auc
#            - save_model=False
#            - n_epochs=200
#            - patience=10
#            - csv_train=[train_all_qualities_1.csv] #,train_all_qualities_2.csv,train_all_qualities_3.csv,train_all_qualities_4.csv
########################################################################################################################
    dr_grade_quality_multi_task:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train_multi_task
          flags:
            - n_classes=18
#            - model_name=[resnet50,resnext50, resnet50_sws,resnext50_sws] #resnet50,resnext50, resnet50_sws,resnext50_sws
#            - load_checkpoint=[no]
            - model_name=[resnet50] #resnet50,resnext50, resnet50_sws,resnext50_sws
            - load_checkpoint=[models/resnet50_eyepacs]
            - pretrained=True
            - base_loss=[ce]
            - lr=[0.0001]
            - lambd=0 
            - exp=1
            - batch_size=8
            - optimizer=sgd
            - oversample=1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
            - decay_f=0.1
            - metric=auc
            - save_model=False
            - n_epochs=200
            - patience=10
            - csv_train=[train_all_qualities_1.csv,train_all_qualities_2.csv,train_all_qualities_3.csv,train_all_qualities_4.csv]
#########################################################################################################################
    dr_grade_quality:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - n_classes=2
            - model_name=[resnet50,resnet50_sws,resnext50,resnext50_sws]
            - pretrained=True
            - base_loss=[ce,focal_loss]
            - load_checkpoint=[no] #,models/resnet50_eyepacs
            - lr=[0.001,0.0001]
            - lambd=0
            - exp=1
            - batch_size=8
            - optimizer=sgd
            - oversample=1/1 # for quality
            - decay_f=0.1
            - metric=auc
            - save_model=False
            - n_epochs=50
            - patience=5
            - csv_train=[train_q_1.csv,train_q_2.csv,train_q_3.csv,train_q_4.csv]
########################################################################################################################
    dr_grade_artifact:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - n_classes=6
            - model_name=[resnet50,resnet50_sws,resnext50,resnext50_sws]
            - pretrained=True
            - base_loss=[ce,focal_loss]
            - load_checkpoint=[no] #,models/resnet50_eyepacs
            - lr=[0.001,0.0001]
            - lambd=0
            - exp=1
            - batch_size=8
            - optimizer=sgd
            - oversample=1/5/1/2/2/5 # for artifact
            - decay_f=0.1
            - metric=auc
            - save_model=False
            - n_epochs=50
            - patience=5
            - csv_train=[train_artifact_1.csv,train_artifact_2.csv,train_artifact_3.csv,train_artifact_4.csv]
########################################################################################################################
    dr_grade_clarity:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - n_classes=5
            - model_name=[resnet50,resnet50_sws,resnext50,resnext50_sws]
            - pretrained=True
            - base_loss=[ce,focal_loss]
            - load_checkpoint=[no] #,models/resnet50_eyepacs
            - lr=[0.001,0.0001]
            - lambd=0 #[0,0.1,1,10]
            - exp=1
            - batch_size=8
            - optimizer=sgd
            - oversample=8/3/1/1/1 # for clarity
            - decay_f=0.1
            - metric=auc
            - save_model=False
            - n_epochs=50
            - patience=5
            - csv_train=[train_clarity_1.csv,train_clarity_2.csv,train_clarity_3.csv,train_clarity_4.csv]
########################################################################################################################
    dr_grade_field_def:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - n_classes=5
            - model_name=[resnet50,resnet50_sws,resnext50,resnext50_sws]
            - pretrained=True
            - base_loss=[ce,focal_loss]
            - load_checkpoint=[no] #,models/resnet50_eyepacs
            - lr=[0.001,0.0001]
            - lambd=0 #[0,0.1,1,10]
            - exp=1
            - batch_size=8
            - optimizer=sgd
            - oversample=10/4/1/1/1 # for field_def
            - decay_f=0.1
            - metric=auc
            - save_model=False
            - n_epochs=50
            - patience=5
            - csv_train=[train_field_def_1.csv,train_field_def_2.csv,train_field_def_3.csv,train_field_def_4.csv]


