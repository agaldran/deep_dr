- model: eyepacs
  description: DR grading on eyepacs
  sourcecode:
    # Source code config at the model level applies to all
    # operations. In this case we want to copy all of the text files
    # (the default configuration) but exclude everything under 'data'.
    - exclude: 'data/*'
    - exclude: 'experiments/*'

  operations:
    train:
      # The default 'main' attribute is 'train' based on the
      # operation name. While we could omit this below, it's good
      # practice to specify it.
      main: train

      # In this configuration, we require the project 'data'
      # directory. Guild creates a symbolic link named 'data' to
      # this directory in each run directory for the operation.
      requires:
        - file: data
        - file: experiments
        - file: utils
        - file: models
        - file: results

    train_multi_task:
      # The default 'main' attribute is 'train' based on the
      # operation name. While we could omit this below, it's good
      # practice to specify it.
      main: train_multi_task
      # In this configuration, we require the project 'data'
      # directory. Guild creates a symbolic link named 'data' to
      # this directory in each run directory for the operation.
      requires:
        - file: data
        - file: experiments
        - file: utils
        - file: models
        - file: results

    test_experiment_class:
      description:
        This is a test experiment with one epoch to check that guild.ai works
      steps:
        - run: train
          flags:
            - csv_train='train.csv'
            - lr=0.01
            - optimizer=['sgd','adam']
            - n_epochs=3
            - save_model=True

########################################################################################################################
    template_class_experiment:
      description:
        This is a template for a classification experiment.
        Write here conclusions.
      steps:
        - run: train
          flags:
            - csv_train=train.csv
            - model_name=[resnet18_cifar,resnet50_cifar,resnet18,resnet50,resnext50,resnext101]
            - pretrained=[True,False]
            - loss_fn=[CE,ULS,GLS,trivial_ot]
            - lr=0.001
            - batch_size=8
            - optimizer=[adam,sgd]
            - oversample=[1/1/1,1/2/1/6/7]
            - n_epochs=100
            - patience=20
            - decay_f=0.1
            - metric=[kappa,kappa_auc_avg]
            - save_model=False

########################################################################################################################
    dr_grade:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - csv_train=train_mac.csv
            - model_name=resnet50
            - pretrained=True
            - base_loss=[ce,gls]
            - lambd=[0,0.1,1,10]
            - exp=[2]
            - lr=0.001
            - batch_size=8
            - optimizer=sgd
            - oversample=1/4/2/2/7
            - decay_f=0.1
            - metric=kappa
            - save_model=True
            - n_epochs=50
            - patience=5
########################################################################################################################
    dr_grade_OD:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - csv_train=[train_od.csv] #
            - model_name=resnet50
            - pretrained=True
            - base_loss=[gls,ce,focal_loss]
            - load_checkpoint=[models/resnet50_eyepacs]
            - lr=[0.0001]
            - lambd=10
            - exp=[1,2]
            - batch_size=8
            - optimizer=sgd
            - oversample=1/4/2/2/7 # 1/2/2/4/9 for UW
            - decay_f=0.1
            - metric=[auc,kappa]
            - save_model=False
            - n_epochs=50
            - patience=5
########################################################################################################################
    dr_grade_MAC:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - csv_train=[train_mac.csv] #
            - model_name=resnet50
            - pretrained=True
            - base_loss=[gls,ce,focal_loss]
            - load_checkpoint=[models/resnet50_eyepacs]
            - lr=[0.0001]
            - lambd=10
            - exp=[1,2]
            - batch_size=8
            - optimizer=sgd
            - oversample=1/4/2/2/7 # 1/2/2/4/9 for UW
            - decay_f=0.1
            - metric=[auc,kappa]
            - save_model=False
            - n_epochs=50
            - patience=5
########################################################################################################################
    dr_grade_ALL:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - csv_train=[train_all.csv] #
            - model_name=resnet50
            - pretrained=True
            - base_loss=[gls,ce,focal_loss]
            - load_checkpoint=[models/resnet50_eyepacs]
            - lr=[0.0001]
            - lambd=10
            - exp=[1,2]
            - batch_size=8
            - optimizer=sgd
            - oversample=1/4/2/2/7 # 1/2/2/4/9 for UW
            - decay_f=0.1
            - metric=[auc,kappa]
            - save_model=False
            - n_epochs=50
            - patience=5
########################################################################################################################
    dr_grade_MAC_UW_AUC:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - csv_train=[train_mac_UW.csv]
            - model_name=[resnet50]
            - pretrained=True
            - base_loss=[gls,ce,focal_loss]
            - load_checkpoint=[experiments/best_auc_mac_20Mar,models/resnet50_eyepacs]
            - lr=0.0001
            - lambd=10
            - exp=[1,2]
            - batch_size=8
            - optimizer=sgd
            - oversample=[1/2/2/4/9] # for UW
            - decay_f=0.1
            - metric=[auc]
            - save_model=False
            - n_epochs=50
            - patience=5
########################################################################################################################
    dr_grade_MAC_UW_KAPPA:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - csv_train=[train_mac_UW.csv]
            - model_name=[resnet50]
            - pretrained=True
            - base_loss=[gls,ce,focal_loss]
            - load_checkpoint=[experiments/best_kappa_mac_20Mar,models/resnet50_eyepacs]
            - lr=0.0001
            - lambd=10
            - exp=[1,2]
            - batch_size=8
            - optimizer=sgd
            - oversample=[1/2/2/4/9] # for UW
            - decay_f=0.1
            - metric=[kappa]
            - save_model=False
            - n_epochs=50
            - patience=5
########################################################################################################################
    dr_grade_OD_UW_AUC:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - csv_train=[train_od_UW.csv]
            - model_name=[resnet50]
            - pretrained=True
            - base_loss=[ce,gls,focal_loss]
            - load_checkpoint=[experiments/best_kappa_od_20Mar,models/resnet50_eyepacs]
            - lr=0.0001
            - lambd=10
            - exp=[1,2]
            - batch_size=8
            - optimizer=sgd
            - oversample=[1/2/2/4/9] # for UW
            - decay_f=0.1
            - metric=[auc]
            - save_model=False
            - n_epochs=50
            - patience=5
########################################################################################################################
    dr_grade_OD_UW_KAPPA:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - csv_train=[train_od_UW.csv]
            - model_name=[resnet50]
            - pretrained=True
            - base_loss=[ce,gls,focal_loss]
            - load_checkpoint=[experiments/best_auc_od_20Mar,models/resnet50_eyepacs]
            - lr=0.0001
            - lambd=10
            - exp=[1,2]
            - batch_size=8
            - optimizer=sgd
            - oversample=[1/2/2/4/9] # for UW
            - decay_f=0.1
            - metric=[kappa]
            - save_model=False
            - n_epochs=50
            - patience=5
########################################################################################################################
    dr_grade_ALL_UW_AUC:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - csv_train=[train_all_UW.csv]
            - model_name=[resnet50]
            - pretrained=True
            - base_loss=[ce,gls,focal_loss]
            - load_checkpoint=[experiments/best_auc_both_20Mar,models/resnet50_eyepacs]
            - lr=0.0001
            - lambd=10
            - exp=[1,2]
            - batch_size=8
            - optimizer=sgd
            - oversample=[1/1/1/3/8] # for UW_all
            - decay_f=0.1
            - metric=[auc]
            - save_model=False
            - n_epochs=50
            - patience=5
########################################################################################################################
    dr_grade_ALL_UW_KAPPA:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - csv_train=[train_all_UW.csv]
            - model_name=[resnet50]
            - pretrained=True
            - base_loss=[ce,gls,focal_loss]
            - load_checkpoint=[experiments/best_kappa_both_20Mar,models/resnet50_eyepacs]
            - lr=0.0001
            - lambd=10
            - exp=[1,2]
            - batch_size=8
            - optimizer=sgd
            - oversample=[1/1/1/3/8] # for UW_all
            - decay_f=0.1
            - metric=[kappa]
            - save_model=False
            - n_epochs=50
            - patience=5

########################################################################################################################
########################################################################################################################
########################################################################################################################
########################################################################################################################
    dr_grade_from_eyepacs_quality_multi_task:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train_multi_task
          flags:
            - csv_train=train_all_qualities.csv
            - n_classes=18
            - model_name=[resnet50]
            - pretrained=True
            - base_loss=[ce,focal_loss]
            - load_checkpoint=[models/resnet50_eyepacs]
            - lr=[0.001,0.0001]
            - lambd=0 
            - exp=1
            - batch_size=8
            - optimizer=sgd
           # - oversample=1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1/1
            - decay_f=0.1
            - metric=auc
            - save_model=False
            - n_epochs=200
            - patience=10

    dr_grade_from_eyepacs_quality:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - csv_train=train_quality.csv
            - n_classes=2
            - model_name=[resnet50,resnet50_sws,resnext50,resnext50_sws]
            - pretrained=True
            - base_loss=[ce,focal_loss]
            - load_checkpoint=[no] #,models/resnet50_eyepacs
            - lr=[0.001,0.0001]
            - lambd=0 #[0,0.1,1,10]
            - exp=1
            - batch_size=8
            - optimizer=sgd
            - oversample=1/1 # for quality
            - decay_f=0.1
            - metric=auc
            - save_model=False
            - n_epochs=50
            - patience=5

########################################################################################################################
    dr_grade_from_eyepacs_artifact:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - csv_train=train_artifact.csv
            - n_classes=6
            - model_name=[resnet50,resnet50_sws,resnext50,resnext50_sws]
            - pretrained=True
            - base_loss=[ce,focal_loss]
            - load_checkpoint=[no] #,models/resnet50_eyepacs
            - lr=[0.001,0.0001]
            - lambd=0 #[0,0.1,1,10]
            - exp=1
            - batch_size=8
            - optimizer=sgd
            - oversample=1/5/1/2/2/5 # for artifact
            - decay_f=0.1
            - metric=auc
            - save_model=False
            - n_epochs=50
            - patience=5

########################################################################################################################
    dr_grade_from_eyepacs_clarity:
      description:
        This is the main experiment on dr grading
      steps:
        - run: train
          flags:
            - csv_train=[train_clarity.csv]
            - n_classes=5
            - model_name=[resnet50,resnet50_sws,resnext50,resnext50_sws]
            - pretrained=True
            - base_loss=[ce,focal_loss]
            - load_checkpoint=[no] #,models/resnet50_eyepacs
            - lr=[0.001,0.0001]
            - lambd=0 #[0,0.1,1,10]
            - exp=1
            - batch_size=8
            - optimizer=sgd
            - oversample=8/3/1/1/1 # for clarity
            - decay_f=0.1
            - metric=auc
            - save_model=False
            - n_epochs=50
            - patience=5

########################################################################################################################
    dr_grade_from_eyepacs_field_def:
      description:
        This is the main experiment on dr grading
        # python train.py --csv_train field_def.csv --n_classes 5 --load_checkpoint models/resnet50_eyepacs
      steps:
        - run: train
          flags:
            - csv_train=[train_field_def.csv]
            - n_classes=5
            - model_name=[resnet50,resnet50_sws,resnext50,resnext50_sws]
            - pretrained=True
            - base_loss=[ce,focal_loss]
            - load_checkpoint=[no] #,models/resnet50_eyepacs
            - lr=[0.001,0.0001]
            - lambd=0 #[0,0.1,1,10]
            - exp=1
            - batch_size=8
            - optimizer=sgd
            - oversample=10/4/1/1/1 # for field_def
            - decay_f=0.1
            - metric=auc
            - save_model=False
            - n_epochs=50
            - patience=5



