
@article{iandola_squeezenet:_2016,
	title = {{SqueezeNet}: {AlexNet}-level accuracy with 50x fewer parameters and {\textless}0.5MB model size},
	shorttitle = {{SqueezeNet}},
	abstract = {Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet). The SqueezeNet architecture is available for download here: https://github.com/DeepScale/SqueezeNet},
	urldate = {2018-10-02},
	author = {Iandola, Forrest N. and Han, Song and Moskewicz, Matthew W. and Ashraf, Khalid and Dally, William J. and Keutzer, Kurt},
	month = feb,
	year = {2016},
	note = {arXiv: 1602.07360},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: In ICLR Format}
}

@article{moccia_learning-based_2018,
	title = {Learning-based classification of informative laryngoscopic frames},
	volume = {158},
	issn = {0169-2607},
	url = {http://www.sciencedirect.com/science/article/pii/S0169260717312130},
	doi = {10.1016/j.cmpb.2018.01.030},
	abstract = {Background and Objective: Early-stage diagnosis of laryngeal cancer is of primary importance to reduce patient morbidity. Narrow-band imaging (NBI) endoscopy is commonly used for screening purposes, reducing the risks linked to a biopsy but at the cost of some drawbacks, such as large amount of data to review to make the diagnosis. The purpose of this paper is to present a strategy to perform automatic selection of informative endoscopic video frames, which can reduce the amount of data to process and potentially increase diagnosis performance. Methods: A new method to classify NBI endoscopic frames based on intensity, keypoint and image spatial content features is proposed. Support vector machines with the radial basis function and the one-versus-one scheme are used to classify frames as informative, blurred, with saliva or specular reflections, or underexposed. Results: When tested on a balanced set of 720 images from 18 different laryngoscopic videos, a classification recall of 91\% was achieved for informative frames, significantly overcoming three state of the art methods (Wilcoxon rank-signed test, significance level = 0.05). Conclusions: Due to the high performance in identifying informative frames, the approach is a valuable tool to perform informative frame selection, which can be potentially applied in different fields, such us computer-assisted diagnosis and endoscopic view expansion.},
	urldate = {2018-10-02},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Moccia, Sara and Vanone, Gabriele O. and Momi, Elena De and Laborai, Andrea and Guastini, Luca and Peretti, Giorgio and Mattos, Leonardo S.},
	month = may,
	year = {2018},
	keywords = {Endoscopy, Frame selection, Larynx, Supervised classification},
	pages = {21--30}
}

@inproceedings{kingma_adam:_2015,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	volume = {5},
	booktitle = {International {Conference} on {Learning} {Representations} ({ICLR})},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	year = {2015}
}

@inproceedings{he_deep_2016,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	doi = {10.1109/CVPR.2016.90},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {He, K. and Zhang, X. and Ren, S. and Sun, J.},
	month = jun,
	year = {2016},
	keywords = {Training, image classification, Degradation, image recognition, object detection, Complexity theory, Neural networks, learning (artificial intelligence), Visualization, CIFAR-10, COCO object detection dataset, COCO segmentation, ILSVRC \& COCO 2015 competitions, ILSVRC 2015 classification task, ImageNet dataset, ImageNet localization, ImageNet test set, VGG nets, deep residual learning, deep residual nets, deeper neural network training, residual function learning, residual nets, visual recognition tasks, neural nets, Image segmentation, Image recognition},
	pages = {770--778}
}

@inproceedings{szegedy_rethinking_2016,
	title = {Rethinking the {Inception} {Architecture} for {Computer} {Vision}},
	booktitle = {The {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	month = jun,
	year = {2016}
}

@article{piazza_narrow_2012,
	title = {Narrow band imaging in endoscopic evaluation of the larynx:},
	volume = {20},
	issn = {1068-9508},
	shorttitle = {Narrow band imaging in endoscopic evaluation of the larynx},
	url = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00020840-201212000-00009},
	doi = {10.1097/MOO.0b013e32835908ac},
	language = {en},
	number = {6},
	urldate = {2018-10-15},
	journal = {Current Opinion in Otolaryngology \& Head and Neck Surgery},
	author = {Piazza, Cesare and Del Bon, Francesca and Peretti, Giorgio and Nicolai, Piero},
	month = dec,
	year = {2012},
	pages = {472--476}
}

@article{schuster_laryngoscopic_2012,
	title = {Laryngoscopic {Image} {Stitching} for {View} {Enhancement} and {Documentation} – {First} {Experiences}},
	volume = {57},
	doi = {10.1515/bmt-2012-4471},
	number = {SI-1 Track-H},
	urldate = {2018-10-15},
	journal = {Biomedical Engineering / Biomedizinische Technik},
	author = {Schuster, Maria and Bergen, Tobias and Reiter, Maximilian and Münzenmayer, Christian and Friedl, Sven and Wittenberg, Thomas},
	year = {2012},
	pages = {704--707}
}

@inproceedings{moccia_automatic_2016,
	title = {Automatic workflow for narrow-band laryngeal video stitching},
	doi = {10.1109/EMBC.2016.7590917},
	abstract = {In narrow band (NB) laryngeal endoscopy, the clinician usually positions the endoscope near the tissue for a correct inspection of possible vascular pattern alterations, indicative of laryngeal malignancies. The video is usually reviewed many times to refine the diagnosis, resulting in loss of time since the salient frames of the video are mixed with blurred, noisy, and redundant frames caused by the endoscope movements. The aim of this work is to provide to the clinician a unique larynx panorama, obtained through an automatic frame selection strategy to discard non-informative frames. Anisotropic diffusion filtering was exploited to lower the noise level while encouraging the selection of meaningful image features, and a feature-based stitching approach was carried out to generate the panorama. The frame selection strategy, tested on on six pathological NB endoscopic videos, was compared with standard strategies, as uniform and random sampling, showing higher performance of the subsequent stitching procedure, both visually, in terms of vascular structure preservation, and numerically, through a blur estimation metric.},
	booktitle = {38th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Moccia, S. and Penza, V. and Vanone, G. O. and Momi, E. De and Mattos, L. S.},
	month = aug,
	year = {2016},
	keywords = {Humans, medical image processing, image filtering, Pipelines, Anisotropic magnetoresistance, Image edge detection, cancer, Image Processing, Computer-Assisted, anisotropic diffusion filtering, Video Recording, Anisotropy, video signal processing, Standards, feature selection, endoscopes, Endoscopy, Larynx, Endoscopes, automatic frame selection strategy, blur estimation metric, endoscope movements, feature-based stitching approach, image feature selection, laryngeal endoscopy, laryngeal malignancy, Laryngeal Neoplasms, larynx panorama, narrow-band laryngeal video stitching, Niobium, noise level, pathological narrow-band endoscopic video, vascular pattern, vascular structure preservation, Workflow},
	pages = {1188--1191}
}

@inproceedings{moccia_vocal_2015,
	title = {Vocal {Folds} {Disorders} {Detection} and {Classification} in {Endoscopic} {Narrow}-{Band} {Images}},
	abstract = {The diagnosis of vocal folds (VF) diseases is error- prone due to the large variety of diseases that can affect them. VF lesions can be divided in nodular, e.g. nodules, polyps and cysts, and diffuse, e.g. hyperplastic laryngitis and carcinoma. By endoscopic examination, the clinician traditionally evaluates the presence of macroscopic formations and mucosal vessels alteration. Endoscopic narrow-band imaging (NBI) has recently started to be employed since it provides enhanced vessels contrast as compared to classical white-light endoscopy. This work presents a preliminary study on the development of an automatic diagnostic tool based on the assessment of vocal cords symmetry in NBI images. The objective is to identify possible protruding mass lesions on which subsequent vessels analysis may be performed. The method proposed here is based on the segmentation of the glottal area (GA) from the endoscopic images, based on which the right and the left portions of the vocal folds are detected and analyzed for the detection of protruding areas. The obtained information is then used to classify the VF edges as healthy or pathological. Results from the analysis of 22 endoscopic NBI images demonstrated that the proposed algorithm is robust and effective, providing a 100\% success rate in the classification of VF edges as healthy or pathological. Such results support the investment in further research to expand and improve the algorithm presented here, potentially with the addition of vessels analysis to determine the pathological classification of detected protruding areas.},
	language = {eng},
	urldate = {2018-10-15},
	author = {Moccia, Sara and De Momi, Elena and Baselli, Giuseppe and Mattos, Leonardo S.},
	year = {2015},
	pages = {50--53}
}

@article{lohscheller_clinically_2007,
	title = {Clinically evaluated procedure for the reconstruction of vocal fold vibrations from endoscopic digital high-speed videos},
	volume = {11},
	issn = {1361-8415},
	url = {https://www.medicalimageanalysisjournal.com/article/S1361-8415(07)00036-9/fulltext},
	doi = {10.1016/j.media.2007.04.005},
	language = {English},
	number = {4},
	urldate = {2018-10-15},
	journal = {Medical Image Analysis},
	author = {Lohscheller, Jörg and Toy, Hikmet and Rosanowski, Frank and Eysholdt, Ulrich and Döllinger, Michael},
	month = aug,
	year = {2007},
	pmid = {17544839},
	keywords = {Image segmentation, Clinical application, High-speed imaging, Vocal folds},
	pages = {400--413}
}

@article{luo_vision-based_2017,
	title = {Vision-{Based} {Surgical} {Field} {Defogging}},
	volume = {36},
	issn = {0278-0062},
	doi = {10.1109/TMI.2017.2701861},
	abstract = {Fogged surgical field visualization that is a common and potentially harmful problem can lead to inappropriate device use and incorrectly targeted tissue and increase surgical risks in endoscopic surgery. This paper aims to remove fog or smoke on endoscopic video sequences to augment and maintain a direct and clear visualization of the operating field. A new visibility-driven fusion defogging framework is proposed for surgical endoscopic video processing. This framework first recovers the visibility and enhances the contrast of hazy images. To address the color infidelity problem introduced by the visibility recovery, the luminances of the recovered and enhanced images are fused in the gradient domain, and the fused luminance is reconstructed by solving the Poisson equation in the frequency domain. The proposed method is evaluated on clinical videos that were collected from prostate cancer surgery. The experimental results demonstrate that the proposed framework defogs endoscopic images more robustly than currently available methods. Additionally, our method also provides an effective way to improve the visual quality of medical or high-dynamic range images.},
	number = {10},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Luo, X. and McLeod, A. J. and Pautler, S. E. and Schlachta, C. M. and Peters, T. M.},
	month = oct,
	year = {2017},
	keywords = {Algorithms, Atmospheric modeling, biomedical optical imaging, cancer, clinical videos, color infidelity problem, dehazing, endoscopes, endoscopic images, endoscopic surgery, endoscopic video sequences, endoscopy, fogged surgical field visualization, frequency domain, frequency-domain analysis, fused luminance, gradient domain, hazy image contrast enhancement, high-dynamic range images, Humans, Image color analysis, image defogging, image enhancement, Image Enhancement, image fusion, image reconstruction, Image restoration, image sequences, incorrectly targeted tissue, Male, medical image processing, Minimally invasive surgery, operating field visualization, Poisson equation, Prostate, prostate cancer surgery, Prostatectomy, Prostatic Neoplasms, Robustness, surgery, Surgery, surgical endoscopic video processing, surgical risks, surgical vision, tumours, Video sequences, video signal processing, Video-Assisted Surgery, visibility recovery, visibility-driven fusion defogging framework, vision, vision-based surgical field defogging, Visualization},
	pages = {2021--2030}
}

@article{galdran_image_2018,
	title = {Image dehazing by artificial multiple-exposure image fusion},
	volume = {149},
	issn = {0165-1684},
	url = {http://www.sciencedirect.com/science/article/pii/S0165168418301063},
	doi = {10.1016/j.sigpro.2018.03.008},
	abstract = {Bad weather conditions can reduce visibility on images acquired outdoors, decreasing their visual quality. The image processing task concerned with the mitigation of this effect is known as image dehazing. In this paper we present a new image dehazing technique that can remove the visual degradation due to haze without relying on the inversion of a physical model of haze formation, but respecting its main underlying assumptions. Hence, the proposed technique avoids the need of estimating depth in the scene, as well as costly depth map refinement processes. To achieve this goal, the original hazy image is first artificially under-exposed by means of a sequence of gamma-correction operations. The resulting set of multiply-exposed images is merged into a haze-free result through a multi-scale Laplacian blending scheme. A detailed experimental evaluation is presented in terms of both qualitative and quantitative analysis. The obtained results indicate that the fusion of artificially under-exposed images can effectively remove the effect of haze, even in challenging situations where other current image dehazing techniques fail to produce good-quality results. An implementation of the technique is open-sourced for reproducibility (https://github.com/agaldran/amef\_dehazing).},
	urldate = {2018-10-16},
	journal = {Signal Processing},
	author = {Galdran, A.},
	month = aug,
	year = {2018},
	keywords = {Fog removal, Gamma correction, Image dehazing, Image fusion, Laplacian pyramid, Multi-exposure image fusion},
	pages = {135--147}
}