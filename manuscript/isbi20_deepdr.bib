
@article{gulshan_development_2016,
	title = {Development and {Validation} of a {Deep} {Learning} {Algorithm} for {Detection} of {Diabetic} {Retinopathy} in {Retinal} {Fundus} {Photographs}},
	volume = {316},
	issn = {0098-7484},
	number = {22},
	urldate = {2017-07-24},
	journal = {JAMA},
	author = {Gulshan, Varun and Peng, Lily and Coram, Marc and Stumpe, Martin C. and Wu, Derek and Narayanaswamy, Arunachalam and Venugopalan, Subhashini and Widner, Kasumi and Madams, Tom and Cuadros, Jorge and Kim, Ramasamy and Raman, Rajiv and Nelson, Philip C. and Mega, Jessica L. and Webster, Dale R.},
	month = dec,
	year = {2016},
	pages = {2402--2410},
	file = {Full Text PDF:/home/agaldran/.zotero/zotero/tp64i87z.default/zotero/storage/EEQS6XK6/Gulshan et al. - 2016 - Development and Validation of a Deep Learning Algo.pdf:application/pdf;Snapshot:/home/agaldran/.zotero/zotero/tp64i87z.default/zotero/storage/XK6PFJKV/2588763.html:text/html}
}

@article{galdran_non-uniform_2020,
	title = {Non-{Uniform} {Label} {Smoothing} for {Diabetic} {Retinopathy} {Grading} from {Retinal} {Fundus} {Images} with {Deep} {Neural} {Networks}},
	journal = {Translational vision science and technology - under review},
	author = {Galdran, Adrian and Chelbi, Jihed and Kobi, Riadh and Dolz, José and Lombaert, Hervé and ben Ayed, Ismail and Chakor, Chakor},
	month = mar,
	year = {2020}
}

@misc{noauthor_who_nodate,
	title = {{WHO} - {Global} report on diabetes - http://www.who.int/diabetes/global-report/en/},
	url = {http://www.who.int/diabetes/global-report/en/},
	abstract = {WHO Global report on diabetes},
	urldate = {2020-03-12},
	journal = {WHO},
	file = {Snapshot:/home/agaldran/.zotero/zotero/tp64i87z.default/zotero/storage/QX785CLE/en.html:text/html}
}

@inproceedings{he_deep_2016,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	doi = {10.1109/CVPR.2016.90},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = jun,
	year = {2016},
	note = {ISSN: 1063-6919},
	keywords = {Training, image classification, Degradation, image recognition, object detection, Complexity theory, Neural networks, learning (artificial intelligence), Visualization, CIFAR-10, COCO object detection dataset, COCO segmentation, ILSVRC \& COCO 2015 competitions, ILSVRC 2015 classification task, ImageNet dataset, ImageNet localization, ImageNet test set, VGG nets, deep residual learning, deep residual nets, deeper neural network training, residual function learning, residual nets, visual recognition tasks, neural nets, Image segmentation, Image recognition},
	pages = {770--778},
	file = {IEEE Xplore Abstract Record:/home/agaldran/.zotero/zotero/tp64i87z.default/zotero/storage/3QHCMB2A/7780459.html:text/html;IEEE Xplore Full Text PDF:/home/agaldran/.zotero/zotero/tp64i87z.default/zotero/storage/GTMT45UE/He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf:application/pdf}
}

@article{fenner_advances_2018,
	title = {Advances in {Retinal} {Imaging} and {Applications} in {Diabetic} {Retinopathy} {Screening}: {A} {Review}},
	volume = {7},
	issn = {2193-8245},
	shorttitle = {Advances in {Retinal} {Imaging} and {Applications} in {Diabetic} {Retinopathy} {Screening}},
	doi = {10.1007/s40123-018-0153-7},
	abstract = {Rising prevalence of diabetes worldwide has necessitated the implementation of population-based diabetic retinopathy (DR) screening programs that can perform retinal imaging and interpretation for extremely large patient cohorts in a rapid and sensitive manner while minimizing inappropriate referrals to retina specialists. While most current screening programs employ mydriatic or nonmydriatic color fundus photography and trained image graders to identify referable DR, new imaging modalities offer significant improvements in diagnostic accuracy, throughput, and affordability. Smartphone-based fundus photography, macular optical coherence tomography, ultrawide-field imaging, and artificial intelligence-based image reading address limitations of current approaches and will likely become necessary as DR becomes more prevalent. Here we review current trends in imaging for DR screening and emerging technologies that show potential for improving upon current screening approaches.},
	language = {eng},
	number = {2},
	journal = {Ophthalmology and Therapy},
	author = {Fenner, Beau J. and Wong, Raymond L. M. and Lam, Wai-Ching and Tan, Gavin S. W. and Cheung, Gemmy C. M.},
	month = dec,
	year = {2018},
	pmid = {30415454},
	pmcid = {PMC6258577},
	keywords = {Retina, Deep learning, Artificial intelligence, Diabetic retinopathy, Optical coherence tomography, Ultrawide field imaging},
	pages = {333--346},
	file = {Full Text:/home/agaldran/.zotero/zotero/tp64i87z.default/zotero/storage/EFJDYI43/Fenner et al. - 2018 - Advances in Retinal Imaging and Applications in Di.pdf:application/pdf}
}

@article{voets_reproduction_2019,
	title = {Reproduction study using public data of: {Development} and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs},
	volume = {14},
	issn = {1932-6203},
	shorttitle = {Reproduction study using public data of},
	abstract = {We have attempted to reproduce the results in Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs, published in JAMA 2016; 316(22), using publicly available data sets. We re-implemented the main method in the original study since the source code is not available. The original study used non-public fundus images from EyePACS and three hospitals in India for training. We used a different EyePACS data set from Kaggle. The original study used the benchmark data set Messidor-2 to evaluate the algorithm’s performance. We used another distribution of the Messidor-2 data set, since the original data set is no longer available. In the original study, ophthalmologists re-graded all images for diabetic retinopathy, macular edema, and image gradability. We have one diabetic retinopathy grade per image for our data sets, and we assessed image gradability ourselves. We were not able to reproduce the original study’s results with publicly available data. Our algorithm’s area under the receiver operating characteristic curve (AUC) of 0.951 (95\% CI, 0.947-0.956) on the Kaggle EyePACS test set and 0.853 (95\% CI, 0.835-0.871) on Messidor-2 did not come close to the reported AUC of 0.99 on both test sets in the original study. This may be caused by the use of a single grade per image, or different data. This study shows the challenges of reproducing deep learning method results, and the need for more replication and reproduction studies to validate deep learning methods, especially for medical image analysis. Our source code and instructions are available at: https://github.com/mikevoets/jama16-retina-replication.},
	language = {en},
	number = {6},
	urldate = {2020-03-15},
	journal = {PLOS ONE},
	author = {Voets, Mike and Møllersen, Kajsa and Bongo, Lars Ailo},
	month = jun,
	year = {2019},
	keywords = {Algorithms, Deep learning, Diabetic retinopathy, Edema, Machine learning algorithms, Neural networks, Open data, Source code},
	pages = {e0217541}
}

@article{krause_grader_2018,
	title = {Grader {Variability} and the {Importance} of {Reference} {Standards} for {Evaluating} {Machine} {Learning} {Models} for {Diabetic} {Retinopathy}},
	volume = {125},
	issn = {0161-6420, 1549-4713},
	language = {English},
	number = {8},
	urldate = {2020-03-15},
	journal = {Ophthalmology},
	author = {Krause, Jonathan and Gulshan, Varun and Rahimy, Ehsan and Karth, Peter and Widner, Kasumi and Corrado, Greg S. and Peng, Lily and Webster, Dale R.},
	month = aug,
	year = {2018},
	pmid = {29548646},
	pages = {1264--1272}
}

@article{lin_focal_2020,
	title = {Focal {Loss} for {Dense} {Object} {Detection}},
	volume = {42},
	issn = {1939-3539},
	abstract = {The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far. In this paper, we investigate why this is the case. We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause. We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training. To evaluate the effectiveness of our loss, we design and train a simple dense detector we call RetinaNet. Our results show that when trained with the focal loss, RetinaNet is able to match the speed of previous one-stage detectors while surpassing the accuracy of all existing state-of-the-art two-stage detectors. Code is at: https://github.com/facebookresearch/Detectron.},
	number = {2},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Dollár, Piotr},
	month = feb,
	year = {2020},
	keywords = {classifier, Computer vision, convolutional neural nets, convolutional neural networks, Convolutional neural networks, cross entropy loss, dense object detection, dense sampling, Detectors, entropy, Entropy, Feature extraction, focal loss, foreground-background class imbalance, image classification, image segmentation, learning (artificial intelligence), machine leaming, machine learning, object detection, Object detection, Proposals, R-CNN, RetinaNet, Training},
	pages = {318--327}
}

@inproceedings{zhao_bira-net_2019,
	title = {{BiRA}-{Net}: {Bilinear} {Attention} {Net} for {Diabetic} {Retinopathy} {Grading}},
	shorttitle = {{BiRA}-{Net}},
	abstract = {Diabetic retinopathy (DR) is a common retinal disease that leads to blindness. For diagnosis purposes, DR image grading aims to provide automatic DR grade classification, which is not addressed in conventional research methods of binary DR image classification. Small objects in the eye images, like lesions and microaneurysms, are essential to DR grading in medical imaging, but they could easily be influenced by other objects. To address these challenges, we propose a new deep learning architecture, called BiRA-Net, which combines the attention model for feature extraction and bilinear model for fine-grained classification. Furthermore, in considering the distance between different grades of different DR categories, we propose a new loss function, called grading loss, which leads to improved training convergence of the proposed approach. Experimental results are provided to demonstrate the superior performance of the proposed approach.},
	booktitle = {2019 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	author = {Zhao, Ziyuan and Zhang, Kerui and Hao, Xuejie and Tian, Jing and Heng Chua, Matthew Chin and Chen, Li and Xu, Xin},
	month = sep,
	year = {2019},
	note = {ISSN: 1522-4880},
	keywords = {automatic DR grade classification, bilinear attention Net, bilinear model, binary DR image classification, biomedical optical imaging, BiRA-Net, conventional research methods, deep learning architecture, Diabetes, diabetic retinopathy, diseases, DR categories, DR grading, DR image grading, eye, eye images, feature extraction, Feature extraction, fine-grained classification, grading loss, image classification, learning (artificial intelligence), medical image processing, medical imaging, microaneurysms, Retina, retinal disease, Retinopathy, Training},
	pages = {1385--1389}
}

@article{araujo_drgraduate_2019,
	title = {{DRGRADUATE}: uncertainty-aware deep learning-based diabetic retinopathy grading in eye fundus images},
	shorttitle = {{DR}\${\textbackslash}vert\${GRADUATE}},
	url = {http://arxiv.org/abs/1910.11777},
	abstract = {Diabetic retinopathy (DR) grading is crucial in determining the patients' adequate treatment and follow up, but the screening process can be tiresome and prone to errors. Deep learning approaches have shown promising performance as computer-aided diagnosis(CAD) systems, but their black-box behaviour hinders the clinical application. We propose DR\${\textbackslash}vert\$GRADUATE, a novel deep learning-based DR grading CAD system that supports its decision by providing a medically interpretable explanation and an estimation of how uncertain that prediction is, allowing the ophthalmologist to measure how much that decision should be trusted. We designed DR\${\textbackslash}vert\$GRADUATE taking into account the ordinal nature of the DR grading problem. A novel Gaussian-sampling approach built upon a Multiple Instance Learning framework allow DR\${\textbackslash}vert\$GRADUATE to infer an image grade associated with an explanation map and a prediction uncertainty while being trained only with image-wise labels. DR\${\textbackslash}vert\$GRADUATE was trained on the Kaggle training set and evaluated across multiple datasets. In DR grading, a quadratic-weighted Cohen's kappa (QWK) between 0.71 and 0.84 was achieved in five different datasets. We show that high QWK values occur for images with low prediction uncertainty, thus indicating that this uncertainty is a valid measure of the predictions' quality. Further, bad quality images are generally associated with higher uncertainties, showing that images not suitable for diagnosis indeed lead to less trustworthy predictions. Additionally, tests on unfamiliar medical image data types suggest that DR\${\textbackslash}vert\$GRADUATE allows outlier detection. The attention maps generally highlight regions of interest for diagnosis. These results show the great potential of DR\${\textbackslash}vert\$GRADUATE as a second-opinion system in DR severity grading.},
	urldate = {2020-03-15},
	journal = {Medical Image Analysis (accepted)},
	author = {Araujo, Teresa and Aresta, Guilherme and Mendonça, Luís and Penas, Susana and Maia, Carolina and Carneiro, Angela and Mendonça, Ana Maria and Campilho, Aurélio},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.11777},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
	annote = {Comment: Submitted to Medical Image Analysis; Figures are compressed due to file size constraints}
}

@article{buda_systematic_2018,
	title = {A systematic study of the class imbalance problem in convolutional neural networks},
	volume = {106},
	issn = {0893-6080},
	abstract = {In this study, we systematically investigate the impact of class imbalance on classification performance of convolutional neural networks (CNNs) and compare frequently used methods to address the issue. Class imbalance is a common problem that has been comprehensively studied in classical machine learning, yet very limited systematic research is available in the context of deep learning. In our study, we use three benchmark datasets of increasing complexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of imbalance on classification and perform an extensive comparison of several methods to address the issue: oversampling, undersampling, two-phase training, and thresholding that compensates for prior class probabilities. Our main evaluation metric is area under the receiver operating characteristic curve (ROC AUC) adjusted to multi-class tasks since overall accuracy metric is associated with notable difficulties in the context of imbalanced data. Based on results from our experiments we conclude that (i) the effect of class imbalance on classification performance is detrimental; (ii) the method of addressing class imbalance that emerged as dominant in almost all analyzed scenarios was oversampling; (iii) oversampling should be applied to the level that completely eliminates the imbalance, whereas the optimal undersampling ratio depends on the extent of imbalance; (iv) as opposed to some classical machine learning models, oversampling does not cause overfitting of CNNs; (v) thresholding should be applied to compensate for prior class probabilities when overall number of properly classified cases is of interest.},
	language = {en},
	urldate = {2020-03-15},
	journal = {Neural Networks},
	author = {Buda, Mateusz and Maki, Atsuto and Mazurowski, Maciej A.},
	month = oct,
	year = {2018},
	keywords = {Class imbalance, Convolutional neural networks, Deep learning, Image classification},
	pages = {249--259}
}

@inproceedings{xie_aggregated_2017,
	title = {Aggregated {Residual} {Transformations} for {Deep} {Neural} {Networks}},
	urldate = {2020-03-15},
	author = {Xie, Saining and Girshick, Ross and Dollar, Piotr and Tu, Zhuowen and He, Kaiming},
	year = {2017},
	pages = {1492--1500}
}

@article{abramoff_improved_2016,
	title = {Improved {Automated} {Detection} of {Diabetic} {Retinopathy} on a {Publicly} {Available} {Dataset} {Through} {Integration} of {Deep} {Learning}},
	volume = {57},
	issn = {1552-5783},
	abstract = {Purpose: To compare performance of a deep-learning enhanced algorithm for automated detection of diabetic retinopathy (DR), to the previously published performance of that algorithm, the Iowa Detection Program (IDP)-without deep learning components-on the same publicly available set of fundus images and previously reported consensus reference standard set, by three US Board certified retinal specialists.
Methods: We used the previously reported consensus reference standard of referable DR (rDR), defined as International Clinical Classification of Diabetic Retinopathy moderate, severe nonproliferative (NPDR), proliferative DR, and/or macular edema (ME). Neither Messidor-2 images, nor the three retinal specialists setting the Messidor-2 reference standard were used for training IDx-DR version X2.1. Sensitivity, specificity, negative predictive value, area under the curve (AUC), and their confidence intervals (CIs) were calculated.
Results: Sensitivity was 96.8\% (95\% CI: 93.3\%-98.8\%), specificity was 87.0\% (95\% CI: 84.2\%-89.4\%), with 6/874 false negatives, resulting in a negative predictive value of 99.0\% (95\% CI: 97.8\%-99.6\%). No cases of severe NPDR, PDR, or ME were missed. The AUC was 0.980 (95\% CI: 0.968-0.992). Sensitivity was not statistically different from published IDP sensitivity, which had a CI of 94.4\% to 99.3\%, but specificity was significantly better than the published IDP specificity CI of 55.7\% to 63.0\%.
Conclusions: A deep-learning enhanced algorithm for the automated detection of DR, achieves significantly better performance than a previously reported, otherwise essentially identical, algorithm that does not employ deep learning. Deep learning enhanced algorithms have the potential to improve the efficiency of DR screening, and thereby to prevent visual loss and blindness from this devastating disease.},
	language = {eng},
	number = {13},
	journal = {Investigative Ophthalmology \& Visual Science},
	author = {Abràmoff, Michael David and Lou, Yiyue and Erginay, Ali and Clarida, Warren and Amelon, Ryan and Folk, James C. and Niemeijer, Meindert},
	month = oct,
	year = {2016},
	pmid = {27701631},
	keywords = {Algorithms, Automation, Diabetic Retinopathy, Diagnosis, Computer-Assisted, Diagnostic Techniques, Ophthalmological, Female, Follow-Up Studies, Humans, Male, Middle Aged, Neural Networks, Computer, Ophthalmologists, Retina, Retrospective Studies, ROC Curve},
	pages = {5200--5206}
}

@article{hand_simple_2001,
	title = {A {Simple} {Generalisation} of the {Area} {Under} the {ROC} {Curve} for {Multiple} {Class} {Classification} {Problems}},
	volume = {45},
	issn = {1573-0565},
	abstract = {The area under the ROC curve, or the equivalent Gini index, is a widely used measure of performance of supervised classification rules. It has the attractive property that it side-steps the need to specify the costs of the different kinds of misclassification. However, the simple form is only applicable to the case of two classes. We extend the definition to the case of more than two classes by averaging pairwise comparisons. This measure reduces to the standard form in the two class case. We compare its properties with the standard measure of proportion correct and an alternative definition of proportion correct based on pairwise comparison of classes for a simple artificial case and illustrate its application on eight data sets. On the data sets we examined, the measures produced similar, but not identical results, reflecting the different aspects of performance that they were measuring. Like the area under the ROC curve, the measure we propose is useful in those many situations where it is impossible to give costs for the different kinds of misclassification.},
	language = {en},
	number = {2},
	urldate = {2020-03-15},
	journal = {Machine Learning},
	author = {Hand, David J. and Till, Robert J.},
	month = nov,
	year = {2001},
	pages = {171--186}
}

@incollection{bertail_bootstrapping_2009,
	title = {On {Bootstrapping} the {ROC} {Curve}},
	urldate = {2020-03-15},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Bertail, Patrice and Clémençcon, Stéphan J. and Vayatis, Nicolas},
	editor = {Koller, D. and Schuurmans, D. and Bengio, Y. and Bottou, L.},
	year = {2009},
	pages = {137--144}
}

@article{de_la_torre_weighted_2018,
	series = {Machine {Learning} and {Applications} in {Artificial} {Intelligence}},
	title = {Weighted kappa loss function for multi-class classification of ordinal data in deep learning},
	volume = {105},
	issn = {0167-8655},
	abstract = {Weighted Kappa is an index of reference used in many diagnosis systems to compare the agreement between different raters. This index can be also used to evaluate the performance of automatic classification methods against the gold standard given by an expert (or from a consensus of an expert group). On the other hand, in the last years, deep learning has achieved a great importance as a new machine learning method. The usual loss function used in deep learning for multi-class classification is the logarithmic loss. In this paper we explore the direct use of a weighted kappa loss function for multi-class classification of ordinal data, also known as ordinal regression. Three classification problems are solved in the paper using these two loss functions. Results confirm that better classification is made when the model is constructed with the optimization of kappa instead of logarithmic loss.},
	language = {en},
	urldate = {2020-03-15},
	journal = {Pattern Recognition Letters},
	author = {de la Torre, Jordi and Puig, Domenec and Valls, Aida},
	month = apr,
	year = {2018},
	keywords = {Computer vision, Convolutional neural networks, Deep learning, Diabetic retinopathy, Supervised learning, Weighted kappa},
	pages = {144--154}
}

@techreport{noauthor_diabetes_nodate,
	title = {Diabetes {Report}, {WHO}},
	url = {https://www.who.int/news-room/fact-sheets/detail/diabetes},
	abstract = {Diabetes is a chronic disease that occurs either when the pancreas does not produce enough insulin or when the body cannot effectively use the insulin it produces.},
	language = {en},
	urldate = {2020-03-15}
}

@article{sahlsten_deep_2019,
	title = {Deep {Learning} {Fundus} {Image} {Analysis} for {Diabetic} {Retinopathy} and {Macular} {Edema} {Grading}},
	volume = {9},
	copyright = {2019 The Author(s)},
	issn = {2045-2322},
	abstract = {Diabetes is a globally prevalent disease that can cause visible microvascular complications such as diabetic retinopathy and macular edema in the human eye retina, the images of which are today used for manual disease screening and diagnosis. This labor-intensive task could greatly benefit from automatic detection using deep learning technique. Here we present a deep learning system that identifies referable diabetic retinopathy comparably or better than presented in the previous studies, although we use only a small fraction of images ({\textless}1/4) in training but are aided with higher image resolutions. We also provide novel results for five different screening and clinical grading systems for diabetic retinopathy and macular edema classification, including state-of-the-art results for accurately classifying images according to clinical five-grade diabetic retinopathy and for the first time for the four-grade diabetic macular edema scales. These results suggest, that a deep learning system could increase the cost-effectiveness of screening and diagnosis, while attaining higher than recommended performance, and that the system could be applied in clinical examinations requiring finer grading.},
	language = {en},
	number = {1},
	urldate = {2020-03-15},
	journal = {Scientific Reports},
	author = {Sahlsten, Jaakko and Jaskari, Joel and Kivinen, Jyri and Turunen, Lauri and Jaanio, Esa and Hietala, Kustaa and Kaski, Kimmo},
	month = jul,
	year = {2019},
	pages = {1--11}
}

@article{valentina_bellemo_artificial_2019,
	title = {Artificial intelligence using deep learning to screen for referable and vision-threatening diabetic retinopathy in {Africa}: a clinical validation study},
	volume = {1},
	issn = {2589-7500},
	shorttitle = {Artificial intelligence using deep learning to screen for referable and vision-threatening diabetic retinopathy in {Africa}},
	abstract = {DOAJ is an online directory that indexes and provides access to quality open access, peer-reviewed journals.},
	language = {en},
	number = {1},
	urldate = {2020-03-15},
	journal = {The Lancet: Digital Health},
	author = {Valentina Bellemo, MSc and Zhan W Lim, PhD and Gilbert Lim, PhD and Quang D Nguyen, BEng and Yuchen Xie, MScPH and Michelle Y T Yip, B. A. and Haslina Hamzah, BSc and Jinyi Ho, Dfst and Xin Q Lee, BSc (Hons) and Wynne Hsu, PhD and Mong L Lee, PhD and Lillian Musonda, M. D. and Manju Chandran, FRCOphth and Grace Chipalo-Mutati, FCOphth (ECSA) and Mulenga Muma, FCOphth (ECSA) and Gavin S W Tan, M. D. and Sobha Sivaprasad, FRCOphth and Geeta Menon, FRCOphth and Tien Y Wong, M. D. and Daniel S W Ting, M. D.},
	month = may,
	year = {2019},
	pages = {e35--e44}
}

@article{costa_weakly-supervised_2018,
	title = {A {Weakly}-{Supervised} {Framework} for {Interpretable} {Diabetic} {Retinopathy} {Detection} on {Retinal} {Images}},
	volume = {6},
	issn = {2169-3536},
	abstract = {Diabetic retinopathy (DR) detection is a critical retinal image analysis task in the context of early blindness prevention. Unfortunately, in order to train a model to accurately detect DR based on the presence of different retinal lesions, typically a dataset with medical expert's annotations at the pixel level is needed. In this paper, a new methodology based on the multiple instance learning (MIL) framework is developed in order to overcome this necessity by leveraging the implicit information present on annotations made at the image level. Contrary to previous MIL-based DR detection systems, the main contribution of the proposed technique is the joint optimization of the instance encoding and the image classification stages. In this way, more useful mid-level representations of pathological images can be obtained. The explainability of the model decisions is further enhanced by means of a new loss function enforcing appropriate instance and mid-level representations. The proposed technique achieves comparable or better results than other recently proposed methods, with 90\% area under the receiver operating characteristic curve (AUC) on Messidor, 93\% AUC on DR1, and 96\% AUC on DR2, while improving the interpretability of the produced decisions.},
	journal = {IEEE Access},
	author = {Costa, Pedro and Galdran, Adrian and Smailagic, Asim and Campilho, AuréLio},
	year = {2018},
	keywords = {bag of visual words, blindness prevention, diabetic retinopathy detection, Dictionaries, diseases, Diseases, DR detection systems, eye, Feature extraction, image annotation, image classification, image classification stages, image level, instance encoding, interpretable diabetic retinopathy detection, learning (artificial intelligence), Lesions, medical image processing, mid-level representations, Multiple instance learning, multiple instance learning framework, pathological images, pixel level, Retina, retinal image analysis, Task analysis, Visualization, weakly-supervised framework},
	pages = {18747--18758}
}

@article{abramoff_automated_2013,
	title = {Automated analysis of retinal images for detection of referable diabetic retinopathy},
	volume = {131},
	issn = {2168-6173},
	abstract = {IMPORTANCE: The diagnostic accuracy of computer detection programs has been reported to be comparable to that of specialists and expert readers, but no computer detection programs have been validated in an independent cohort using an internationally recognized diabetic retinopathy (DR) standard.
OBJECTIVE: To determine the sensitivity and specificity of the Iowa Detection Program (IDP) to detect referable diabetic retinopathy (RDR).
DESIGN AND SETTING: In primary care DR clinics in France, from January 1, 2005, through December 31, 2010, patients were photographed consecutively, and retinal color images were graded for retinopathy severity according to the International Clinical Diabetic Retinopathy scale and macular edema by 3 masked independent retinal specialists and regraded with adjudication until consensus. The IDP analyzed the same images at a predetermined and fixed set point. We defined RDR as more than mild nonproliferative retinopathy and/or macular edema.
PARTICIPANTS: A total of 874 people with diabetes at risk for DR.
MAIN OUTCOME MEASURES: Sensitivity and specificity of the IDP to detect RDR, area under the receiver operating characteristic curve, sensitivity and specificity of the retinal specialists' readings, and mean interobserver difference (κ).
RESULTS: The RDR prevalence was 21.7\% (95\% CI, 19.0\%-24.5\%). The IDP sensitivity was 96.8\% (95\% CI, 94.4\%-99.3\%) and specificity was 59.4\% (95\% CI, 55.7\%-63.0\%), corresponding to 6 of 874 false-negative results (none met treatment criteria). The area under the receiver operating characteristic curve was 0.937 (95\% CI, 0.916-0.959). Before adjudication and consensus, the sensitivity/specificity of the retinal specialists were 0.80/0.98, 0.71/1.00, and 0.91/0.95, and the mean intergrader κ was 0.822.
CONCLUSIONS: The IDP has high sensitivity and specificity to detect RDR. Computer analysis of retinal photographs for DR and automated detection of RDR can be implemented safely into the DR screening pipeline, potentially improving access to screening and health care productivity and reducing visual loss through early treatment.},
	language = {eng},
	number = {3},
	journal = {JAMA ophthalmology},
	author = {Abràmoff, Michael D. and Folk, James C. and Han, Dennis P. and Walker, Jonathan D. and Williams, David F. and Russell, Stephen R. and Massin, Pascale and Cochener, Beatrice and Gain, Philippe and Tang, Li and Lamard, Mathieu and Moga, Daniela C. and Quellec, Gwénolé and Niemeijer, Meindert},
	month = mar,
	year = {2013},
	pmid = {23494039},
	keywords = {Area Under Curve, Diabetic Retinopathy, False Negative Reactions, Female, Humans, Image Interpretation, Computer-Assisted, Macular Edema, Male, Middle Aged, Observer Variation, Ophthalmology, Photography, Predictive Value of Tests, Referral and Consultation, Reproducibility of Results, Retina, ROC Curve, Sensitivity and Specificity},
	pages = {351--357}
}

@article{li_automatic_2019,
	title = {Automatic {Detection} of {Diabetic} {Retinopathy} in {Retinal} {Fundus} {Photographs} {Based} on {Deep} {Learning} {Algorithm}},
	volume = {8},
	issn = {2164-2591},
	language = {en},
	number = {6},
	urldate = {2020-03-15},
	journal = {Translational Vision Science \& Technology},
	author = {Li, Feng and Liu, Zheng and Chen, Hua and Jiang, Minshan and Zhang, Xuedian and Wu, Zhizheng},
	month = nov,
	year = {2019},
	pages = {4--4}
}

@misc{noauthor_american_nodate,
	title = {American academy of ophthalmology. international clinical diabetic retinopathy disease severity scale, detailed table},
	url = {American academy of ophthalmology. international clinical diabetic retinopathy disease severity scale, detailed table.}
}

@article{wilkinson_proposed_2003,
	title = {Proposed international clinical diabetic retinopathy and diabetic macular edema disease severity scales},
	volume = {110},
	issn = {0161-6420, 1549-4713},
	language = {English},
	number = {9},
	urldate = {2020-03-15},
	journal = {Ophthalmology},
	author = {Wilkinson, C. P. and Ferris, Frederick L. and Klein, Ronald E. and Lee, Paul P. and Agardh, Carl David and Davis, Matthew and Dills, Diana and Kampik, Anselm and Pararajasegaram, R. and Verdaguer, Juan T.},
	month = sep,
	year = {2003},
	pmid = {13129861},
	pages = {1677--1682}
}

@incollection{frogner_learning_2015,
	title = {Learning with a {Wasserstein} {Loss}},
	urldate = {2020-03-15},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 28},
	publisher = {Curran Associates, Inc.},
	author = {Frogner, Charlie and Zhang, Chiyuan and Mobahi, Hossein and Araya, Mauricio and Poggio, Tomaso A},
	editor = {Cortes, C. and Lawrence, N. D. and Lee, D. D. and Sugiyama, M. and Garnett, R.},
	year = {2015},
	pages = {2053--2061}
}

@inproceedings{mensch_geometric_2019,
	title = {Geometric {Losses} for {Distributional} {Learning}},
	abstract = {Building upon recent advances in entropy-regularized optimal transport, and upon Fenchel duality between measures and continuous functions, we propose a generalization of the logistic loss that inc...},
	language = {en},
	urldate = {2020-03-15},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Mensch, Arthur and Blondel, Mathieu and Peyré, Gabriel},
	month = may,
	year = {2019},
	pages = {4516--4525}
}

@inproceedings{huang_learning_2016,
	title = {Learning {Deep} {Representation} for {Imbalanced} {Classification}},
	url = {https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Huang_Learning_Deep_Representation_CVPR_2016_paper.html},
	urldate = {2020-03-15},
	author = {Huang, Chen and Li, Yining and Change Loy, Chen and Tang, Xiaoou},
	year = {2016},
	pages = {5375--5384}
}

@inproceedings{zhou_collaborative_2019,
	title = {Collaborative {Learning} of {Semi}-{Supervised} {Segmentation} and {Classification} for {Medical} {Images}},
	urldate = {2020-03-15},
	author = {Zhou, Yi and He, Xiaodong and Huang, Lei and Liu, Li and Zhu, Fan and Cui, Shanshan and Shao, Ling},
	year = {2019},
	pages = {2079--2088}
}

@inproceedings{wang_zoom--net_2017,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Zoom-in-{Net}: {Deep} {Mining} {Lesions} for {Diabetic} {Retinopathy} {Detection}},
	isbn = {978-3-319-66179-7},
	shorttitle = {Zoom-in-{Net}},
	language = {en},
	booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} - {MICCAI} 2017},
	publisher = {Springer International Publishing},
	author = {Wang, Zhe and Yin, Yanxin and Shi, Jianping and Fang, Wei and Li, Hongsheng and Wang, Xiaogang},
	year = {2017},
	pages = {267--275}
}

@article{zhi-hua_zhou_training_2006,
	title = {Training cost-sensitive neural networks with methods addressing the class imbalance problem},
	volume = {18},
	issn = {2326-3865},
	abstract = {This paper studies empirically the effect of sampling and threshold-moving in training cost-sensitive neural networks. Both oversampling and undersampling are considered. These techniques modify the distribution of the training data such that the costs of the examples are conveyed explicitly by the appearances of the examples. Threshold-moving tries to move the output threshold toward inexpensive classes such that examples with higher costs become harder to be misclassified. Moreover, hard-ensemble and soft-ensemble, i.e., the combination of above techniques via hard or soft voting schemes, are also tested. Twenty-one UCl data sets with three types of cost matrices and a real-world cost-sensitive data set are used in the empirical study. The results suggest that cost-sensitive learning with multiclass tasks is more difficult than with two-class tasks, and a higher degree of class imbalance may increase the difficulty. It also reveals that almost all the techniques are effective on two-class tasks, while most are ineffective and even may cause negative effect on multiclass tasks. Overall, threshold-moving and soft-ensemble are relatively good choices in training cost-sensitive neural networks. The empirical study also suggests that some methods that have been believed to be effective in addressing the class imbalance problem may, in fact, only be effective on learning with imbalanced two-class data sets.},
	number = {1},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Zhi-Hua Zhou and Xu-Ying Liu},
	month = jan,
	year = {2006},
	keywords = {class imbalance learning, cost-sensitive learning, cost-sensitive neural network training, Costs, data mining, Data mining, Decision trees, ensemble learning, ensemble learning., Index Terms- Machine learning, learning (artificial intelligence), Learning systems, machine learning, Machine learning, neural nets, neural networks, Neural networks, oversampling technique, sampling, sampling methods, Sampling methods, Testing, threshold-moving, Training data, undersampling technique, Voting},
	pages = {63--77}
}

@inproceedings{thai-nghe_cost-sensitive_2010,
	title = {Cost-sensitive learning methods for imbalanced data},
	booktitle = {The 2010 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Thai-Nghe, Nguyen and Gantner, Zeno and Schmidt-Thieme, Lars},
	month = jul,
	year = {2010},
	keywords = {Cancer, cost sensitive learning methods, CSL, Kernel, learning (artificial intelligence), machine learning, Measurement, Nearest neighbor searches, Noise, pattern classification, Rain, support vector machines, Support vector machines, UCI, user interfaces},
	pages = {1--8}
}

@inproceedings{galdran_cost-sensitive_2020,
	title = {Cost-{Sensitive} {Regularization} for {Diabetic} {Retinopathy} {Grading} from {Eye} {Fundus} {Images}},
	abstract = {ben Ayed},
	booktitle = {{MICCAI} 2020 (under review)},
	author = {Galdran, Adrian and Dolz, Jose and Chakor, Hadi and Lombaert, Hervé and ben Ayed, Ismail},
	year = {2020}
}