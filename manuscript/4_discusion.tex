\section{Discussion and Future Work}
From Fig. \ref{fig_rocs}, we observe that the three fine-tuned CNNs tested in this work exceed previously reported performance in the NBI-InfFrames dataset by a wide margin. Performance metrics demonstrate that the weights learned for the task of natural image classification are indeed useful for identifying informative laryngoscopic frames. Interestingly, the simplest of the three employed models delivered the highest performance, revealing that too much complexity may lead to a slight overfitting, and it may be preferable to opt for moderately expressive architectures to increase generalizability in this setting.

The analysis reported in Table \ref{tab_1_results} shows that both the approach introduced in \cite{moccia_learning-based_2018} and SqueezeNet suffer when assigning the correct category to uninformative frames, whereas the classification into informative frames was almost perfect for the case of the CNN. When classifying uninformative frames into blurry, containing specularities/saliva, and underexposed, the fine-tuned SqueezeNet achieved a slightly lower performance, although the overall median accuracy was high enough so as to consider this simple CNN as an excellent baseline for further research on laryngoscopic frame classification, with a $94\%$ median recall and a $95\%$ median precision. In addition, the inter-quartile range was also lower than in \cite{moccia_learning-based_2018} for every measure, pointing to a great robustness of the proposed approach in this problem.

Our findings indicate that a simple CNN like SqueezeNet suffices to successfully solve the task of informative frame classification in laringoscopies. In addition, the moderate complexity of SqueezeNet turns this approach into an ideal candidate for its introduction in clinical workflows. Its lightweight memory requirements (less than 0.5 MB) enable its embedding even in portable devices, and its fast inference time (one order of magnitude lower than previously reported times) allows for the addition of further image processing or computer vision post-processing modules (\textit{e.g.} abnormality detectors or image quality enhancement techniques) without hindering the potential for real-time execution.

The next step will consist of considering full video processing, where the temporal dimension of the data could be also taken into account by means of Recurrent Neural Networks coupled with CNNs. This may further increase the consistency of predictions, and enable an improved analysis of laryngoscopic frame visual content. Image processing techniques for restoring visibility on un-informative frames based on different exposures \cite{galdran_image_2018} will also be considered.