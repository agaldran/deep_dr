\documentclass{article}
\usepackage{spconf,amsmath,graphicx}
\usepackage[utf8]{inputenc}
\usepackage{xcolor}
\usepackage{blindtext}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage[caption=false]{subfig}
\usepackage{caption} 
\captionsetup[table]{skip=8pt}
%\usepackage{makecell}
%\renewcommand\theadalign{bc}
%\renewcommand\theadfont{\bfseries}
%\renewcommand\theadgape{\Gape[4pt]}
%\renewcommand\cellgape{\Gape[4pt]}
% For subfig.sty:
 \let\MYorigsubfloat\subfloat
 \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}
\usepackage{dblfloatfix}

\newcommand{\ines}{\textcolor{black}}

% Title.
% ------
\title{COST-SENSITIVE LOSS MINIMIZATION FOR RETINAL IMAGE ANALYSIS}


\name{Adrian Galdran$^{\star, \dagger}$, J. Dolz$^{\dagger}$, A. Christodoulidis$^{\ddagger}$, H. Chakor$^{\ddagger}$, H. Lombaert$^{\dagger}$, I. ben Ayed$^{\dagger}$
\thanks{Corresponding author: Adrian Galdran (agaldran@bournemouth.ac.uk).
}
}
\address{$^{\star}$ 
Bournemouth University, UK \\
$^{\dagger}$ École de Technologie Supérieure, University of Quebec, Canada
\\
${\ddagger}$ Diagnos INC., Quebec, Canada
}


\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}
This short paper includes a description of the method employed by our team to address the DEEP-DR challenge. 
We participate in each of the three sub-challenges.
While our solution for sub-challenge 1 (DR grading from fundus images) and sub-challenge 3 (DR grading from UW images) is based on similar ideas, we introduce a different strategy for sub-challenge 2 (fundus image quality assessment). 
In the first case, we rely on a methodology based on Cost-Sensitive regularization adapted to standard CNNs for better performing DR grading. 
This consists of attaching an extra term that acts as a regularizer to standard classification losses, with the goal of imposing greater penalties on predicted grades when they are farther away from the true grade associated to a particular image.
For the latter, we train five different CNNs, four of them meant to solve each of the sub-tasks in sub-challenge 2 independently, and a fifth one that solves the four sub-tasks simultaneously, sharing the same convolutional weights and internal representation but with four different predictive streams in the last part of the architecture.
Our approach performs reasonably well in our internal validation tests as well as in the online validation set. 
Code to reproduce our results is released at \url{github.com/agaldran/deepdr}.
\end{abstract}
%
\begin{keywords}
Diabetic Retinopathy Grading, Cost-Sensitive Classification, Retinal Image Quality Assessment, Ultra-Wide Field Retinal Imaging
\end{keywords}

\input{fig1}

\input{1_introduction}

\input{2_method}
%
%\input{table_1_results}
%
\input{3_evaluation}
%
\input{4_discusion}

%\input{5_conclusion}

\bibliographystyle{abbrv}
%\bibliographystyle{IEEEbib}
%\bibliography{strings,refs}
\bibliography{isbi20_deepdr}

\end{document}